{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yihuang/Documents/CODE/Python_projects/unitcov/forecast_pipeline'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from subprocess import check_output\n",
    "from datetime import date\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and check covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_date(date):\n",
    "    m, d, y = list(map(int, date.split('/')))\n",
    "    date_vec = [y, m, d]\n",
    "    return '20' + '-'.join([str(x).zfill(2) for x in date_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JHU case data shape = (3324, 301)\n",
      "JHU death data shape = (3324, 302)\n"
     ]
    }
   ],
   "source": [
    "url_case = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "url_death = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "df_case = pd.read_csv(url_case).dropna()\n",
    "df_death = pd.read_csv(url_death).dropna()\n",
    "\n",
    "print(f'JHU case data shape = {df_case.shape}')\n",
    "print(f'JHU death data shape = {df_death.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_case = sorted([modify_date(col) for col in df_case.columns if col.endswith('/20')])\n",
    "dates_death = sorted([modify_date(col) for col in df_death.columns if col.endswith('/20')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date check passed? True\n"
     ]
    }
   ],
   "source": [
    "# Date sanity check\n",
    "date_check = (dates_case[0] == dates_death[0]) & (dates_case[-1] == dates_death[-1])\n",
    "print(f'Date check passed? {date_check}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up and save\n",
    "csv_case_fname = url_case.split('/')[-1][:-4] + '_' + dates_case[-1] + '.csv'\n",
    "csv_death_fname = url_death.split('/')[-1][:-4] + '_' + dates_case[-1] + '.csv'\n",
    "\n",
    "existing_case_csv = glob('pipeline_data/time_series_covid19_confirmed_US*csv')\n",
    "existing_death_csv = glob('pipeline_data/time_series_covid19_death_US*csv')\n",
    "if len(existing_case_csv) > 0:\n",
    "    for csv in existing_case_csv:\n",
    "        check_output(f'rm {csv}', shell=True)\n",
    "if len(existing_death_csv) > 0:\n",
    "    for csv in existing_death_csv:\n",
    "        check_output(f'rm {csv}', shell=True)    \n",
    "\n",
    "df_case.to_csv(f'pipeline_data/{csv_case_fname}', index=False)\n",
    "df_death.to_csv(f'pipeline_data/{csv_death_fname}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process covid data and make regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-04-04', '2020-04-11', '2020-04-18', '2020-04-25',\n",
      "               '2020-05-02', '2020-05-09', '2020-05-16', '2020-05-23',\n",
      "               '2020-05-30', '2020-06-06', '2020-06-13', '2020-06-20',\n",
      "               '2020-06-27', '2020-07-04', '2020-07-11', '2020-07-18',\n",
      "               '2020-07-25', '2020-08-01', '2020-08-08', '2020-08-15',\n",
      "               '2020-08-22', '2020-08-29', '2020-09-05', '2020-09-12',\n",
      "               '2020-09-19', '2020-09-26', '2020-10-03', '2020-10-10',\n",
      "               '2020-10-17', '2020-10-24', '2020-10-31', '2020-11-07'],\n",
      "              dtype='datetime64[ns]', freq='7D')\n"
     ]
    }
   ],
   "source": [
    "start = '2020-04-04'\n",
    "end = date.today()\n",
    "dates_ = pd.date_range(start, end, freq='7D')\n",
    "print(dates_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.rename(columns={col: modify_date(col) for col in df_case.columns if col.endswith('/20')}, inplace=True)\n",
    "df_death.rename(columns={col: modify_date(col) for col in df_death.columns if col.endswith('/20')}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = sorted(list(set(df_case.columns.values).intersection([str(d.date()) for d in dates_])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case['FIPS'] = df_case['FIPS'].apply(lambda x: str(int(x)).zfill(5))\n",
    "df_case = df_case.rename(columns={'FIPS': 'fips'}).set_index('fips')\n",
    "df_case = df_case.drop([\n",
    "    'UID', 'iso2', 'iso3', 'code3',\n",
    "    'Admin2', 'Province_State', 'Country_Region', \n",
    "    'Lat', 'Long_', 'Combined_Key'], axis=1)\n",
    "\n",
    "df_case['2020-01-21'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_death['FIPS'] = df_death['FIPS'].apply(lambda x: str(int(x)).zfill(5))\n",
    "df_death = df_death.rename(columns={'FIPS': 'fips'}).set_index('fips')\n",
    "df_death = df_death.drop([\n",
    "    'UID', 'iso2', 'iso3', 'code3',\n",
    "    'Admin2', 'Province_State', 'Country_Region', \n",
    "    'Lat', 'Long_', 'Combined_Key'], axis=1)\n",
    "\n",
    "df_death['2020-01-21'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['2020-01-21'] + dates\n",
    "\n",
    "df_case_step = df_case[cols]\\\n",
    "    .rename(columns={col: f'case{i - 1}' for i, col in enumerate(cols)})\\\n",
    "    .diff(axis=1).dropna(axis=1)\n",
    "df_death_step = df_death[cols]\\\n",
    "    .rename(columns={col: f'death{i - 1}' for i, col in enumerate(cols)})\\\n",
    "    .diff(axis=1).dropna(axis=1)\n",
    "\n",
    "df_covid = pd.concat([df_case_step, df_death_step], axis=1)\n",
    "df_covid[df_covid < 0] = 0\n",
    "\n",
    "with open('pipeline_data/steps.dat', 'w') as handle:\n",
    "    handle.write(' '.join(cols[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup and save\n",
    "existing_data_covid_csv = glob('pipeline_data/data_covid_????-??-??.csv')\n",
    "\n",
    "if len(existing_data_covid_csv) > 0:\n",
    "    for csv in existing_data_covid_csv:\n",
    "        check_output(f'rm {csv}', shell=True)\n",
    "        \n",
    "df_covid.to_csv(f'pipeline_data/data_covid_{dates_case[-1]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load non-covid data and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_covid = pd.read_csv('pipeline_data/data_non-covid.csv', dtype={'fips': str}).set_index('fips')\n",
    "df = df_non_covid.join(df_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup and save\n",
    "existing_data_csv = glob('pipeline_data/data_????-??-??.csv')\n",
    "if len(existing_data_csv) > 0:\n",
    "    for csv in existing_data_csv:\n",
    "        check_output(f'rm {csv}', shell=True)  \n",
    "\n",
    "df.to_csv(f'pipeline_data/data_{dates_case[-1]}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
